# Pythonで学ぶ機械学習/ディープラーニング実践 2回

## TensorFlowの基礎
- TensorFlowとは…
  - Google社が提供しているオープンソースの機械学習ライブラリ
  - ディープラーニング用の機能を実装
  - Pythoh,C++,Java,Goで利用可能
- TensorFlowのインストール
  - `pip install --upgrade tensorflow`

## パーセプトロンの実装
- 単純パーセプトロン
  - 総入力関数
    - $$ y = w_0 + x_1w_1 + x_2w_2 $$
  - 活性化関数
    - $$ h = 1 (y >= 0)
    - $$ h = -1 (y < 0)
  - 誤差関数(正解と計算結果の誤差を表す関数)
    - E = max(0, -wtx)
  - 誤差関数Eを最小にする重みwを求める
    - **勾配降下法**
  - 勾配降下法
    - $$ w = w - \eta \frac{dE}{dw}
    - $$ w_i = w_i - \eta \frac{dE}{dw_1} = tx_i
  - 重みの更新
    - $$ w_{new} = w_{old} + \eta tw_{old}x_{(i)}
  - パーセプトロンでの機械学習
    - 与えられたデータから，重みを機械学習により見つけ出す

## ロジスティック回帰の実装
- シグモイド関数
  - 学習データがどちらの領域に属すか確率で表現する．シグモイド関数を活性化関数として利用する
    - $$ \sigma(x) = \frac{1}{1 + e^{-x}}
- ロジスティック回帰
  - アルゴリズム
    - 総入力関数
    - $$ f(x_1, x_2) = w_0 + w_1x_1 + w_2x_2
  - このデータが正解である確率はシグモイド関数を使い求める
  - この値を出力とする
    - $$ P(x_1,x_2) = \sigma(f(x_1,x_2))
  - アルゴリズム
    - n番目のデータを正しく予測する確率をPnとする
    - 全てのデータを正しく予測する確率Pは以下となりPの最大値を取るような重みを見つける
      - $$ P = P_1P_2P_3...P_n
    - 計算しやすいように対数をとった関数Eを最小化する重みを見つける
      - $$ E = -logP
    - 最終的には以下の誤差関数Eが得られる
      - $$ E = \sum_{n=1}^N[t_nlogP(x_{1n},x_{2n}) + (1 - t_n)log{1 - P(x_{1n}),x_{2n}}]
      - 誤差関数Eの極小値を求めればいい
      - 偏微分方程式をアルゴリズム勾配降下法を使い解を求める
      - $$ \frac{\delta E}{\delta(w_0,w_1,w_2)} = 0

## まとめ
- パーセプトロンとロジスティック回帰の2分類問題を実装
- 計算はTensorFlowが行うので計算モデルをプログラムするだけでよい
