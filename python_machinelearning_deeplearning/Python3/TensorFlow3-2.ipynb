{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 理論\n",
    "\n",
    "## 総入力関数\n",
    "\n",
    "$$\n",
    "y = w^T x+ b\n",
    "$$\n",
    "\n",
    "## softmax関数\n",
    "ロジスティック回帰では、シグモイド関数を使用して、2値分類を行いました。\n",
    "今度は、手書きの数字画像を認識するので、2値ではなく0から9までのどれかに\n",
    "分類する必要があります。このような問題を　**多クラス分類** とよびます。\n",
    "多クラス分類を行う場合は、シグモド関数ではなく、**ソフトマックス関数** と呼ばれる\n",
    "関数を使用します。\n",
    "\n",
    "ソフトマックス関数\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "softmax(y) &= \\frac{exp(x_i)}{ \\sum_{j=1}^{n} exp(x_j)}　\\tag{1.1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "理論上は式(1.1）のようになりますが、このままコンピュータで計算するとオーバーフローを起こすので\n",
    "実際のプログラミングでは以下のように変形します。\n",
    "\n",
    "任意の定数Cを分母分子に掛ける\n",
    "$$\n",
    "\\begin{align}\n",
    "softmax(y) &= \\frac{Cexp(x_i)}{ C\\sum_{j=1}^{n} exp(x_j)}　\\\\\n",
    "&=\\frac{Cexp(x_i + logC)}{ C\\sum_{j=1}^{n} exp(x_j + logC)}　\\\\\n",
    "&=\\frac{Cexp(x_i + C')}{ C\\sum_{j=1}^{n} exp(x_j + C')}　\\tag{1.2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "TensorFlowでは、softmax関数で実装されているので、理論通り考えて差し支えありません。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#数式(1.1)のとおりだとオーバーフローしてしまう。\n",
    "#\n",
    "import numpy as np\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "softmax(np.array([1010,1000,990]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.99954600e-01,   4.53978686e-05,   2.06106005e-09])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#数式(1.2)のとおりだと計算できる\n",
    "#\n",
    "import numpy as np\n",
    "#Cを-1000として\n",
    "C=-1000\n",
    "def softmax2(x):\n",
    "    x\n",
    "    x2 = x + C\n",
    "    return np.exp(x2) / np.sum(np.exp(x2))\n",
    "\n",
    "y = softmax2(np.array([1010,1000,990]))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の例とおおり、ソフトマックス関数の合計は1.0とななる。各値がそれぞれの多クラスの正解ラベルとなる確率を表す。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 確率の表現\n",
    "$N$個の入力データ $x_n(n=1,2,3,\\cdots,n)$ とそれに対応する正解データ　$t_n $ としたときに、<br>\n",
    "$x_n$がクラス$k$に属するときの$t_n$の$j$番目の成分は\n",
    "$$\n",
    "t_{nj}=\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & (j = k) \\\\\n",
    "0 & (j \\neq 0)\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "と表現される。\n",
    "クラス$k$に属する確率は\n",
    "$$\n",
    "\\begin{align}\n",
    "P(C=k | x) &= softmax(w^T + b )  \\\\\n",
    "&=\\frac{Cexp(w_k^T + b)}{ C\\sum_{j=1}^{n} exp(w_k^T + b)}　\\tag{1.3}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### 尤度関数\n",
    "ロジスティクス回帰と同様に尤度関数を考えると、\n",
    "\n",
    "式(1.3)より\n",
    "<br>\n",
    "<br>\n",
    "$$\n",
    "\\begin{align}\n",
    "L(w,b) &=\\prod_{n=1}^{N}\\prod_{k=1}^{K}P(C=t_{nk}|x_n)^{t_{nk}} \\\\\n",
    " &=\\prod_{n=1}^{N}\\prod_{k=1}^{K}y_{nk}^{t_nk} \\tag{1.4}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "尤度関数を最大化する重みを見つければ良いが、尤度関数は積の形をしており、計算を単純化するためには式(1.5)の対数をとり和の形で表現します。\n",
    "得られた誤差関数Eを勾配降下法で最小となる重みを計算します。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E(w,b) &= -logL(w,b) \\\\\n",
    "&= -\\sum_{n=1}^{N}\\sum_{k=1}^{K}t_{nk}logy_{nk} \\tag{1.5}\n",
    "\\end{align}\\\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "誤差関数Eの偏微分は以下のようになる。\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial w_j} &= \n",
    "\\sum_{n=1}^{N}\\sum_{k=1}^{K}\\frac{\\partial }{\\partial y_{nk}}(t_{nk}logy_{nk})\\frac{\\partial y_{nk}}{\\partial a_{nj}} \\frac{\\partial a_{nj}}{\\partial w_{nj}}\\\\\n",
    "&= - \\sum_{n=1}^{N}\\sum_{k=1}^{K}\\frac{t_{nk}}{y_{nk}}  \\frac{\\partial y_{nk}}{\\partial a_{nj}}x_n\\\\\n",
    "&= -  \\sum_{n=1}^{N}\\lgroup\\sum_{k=1}^{K}t_{nk}I_{kj}- \\sum_{k=1}t_{nl}y_{nk})x_n\\\\\n",
    "&=  - \\sum_{n=1}^{N}(t_{nj}-y_{nj})x_n \\tag{1.6}\n",
    "\\end{align}\\\n",
    "$$\n",
    "同様にバイアスに関しても偏微分すると、\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial b_j} &=  - \\sum_{n=1}^{N}(t_{nj}-y_{nj}) 　\\tag{1.7}\n",
    "\\end{align}\\\n",
    "$$\n",
    "\n",
    "最終的に\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial W} &=  - \\sum_{n=1}^{N}(t_{n}-y_{n})X_n^T 　\\tag{1.8}\n",
    "\\end{align}\\\n",
    "$$\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial b} &=  - \\sum_{n=1}^{N}(t_{n}-y_{n})　\\tag{1.9}\n",
    "\\end{align}\\\n",
    "$$\n",
    "\n",
    "\n",
    "が得られる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手書き画像認識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/site-packages\n",
      "Requirement already up-to-date: six>=1.10.0 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: astor>=0.6.0 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: protobuf>=3.4.0 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: termcolor>=1.1.0 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: gast>=0.2.0 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: grpcio>=1.8.6 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: numpy>=1.13.3 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: tensorboard<1.9.0,>=1.8.0 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: wheel>=0.26 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: absl-py>=0.1.6 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorflow)\n",
      "Requirement already up-to-date: html5lib==0.9999999 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "Requirement already up-to-date: werkzeug>=0.11.10 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "Requirement already up-to-date: bleach==1.5.0 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "Requirement already up-to-date: markdown>=2.6.8 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "! pip3 install --upgrade tensorflow\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "#MNISTデータがダウンロードできない場合は、ファイルをMNIST_data\n",
    "#ディレクトリに展開して、以下の行を実行すると\n",
    "#取り込めます\n",
    "#mnist = input_data.read_data_sets('MNIST_data',one_hot=True)   \n",
    "images, labels = mnist.train.next_batch(10)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdMAAADlCAYAAAAIqh2pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPLEzJSIi8sTOlIiIyBM7UyIiIk//H1BUjjaBrt8iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114187898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "for c, (image, label) in enumerate(zip(images, labels),start=1):\n",
    "    subplot = fig.add_subplot(2,5,c)\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    subplot.set_title('%d' % np.argmax(label))\n",
    "    subplot.imshow(image.reshape((28,28)), vmin=0, vmax=1,\n",
    "                   cmap=plt.cm.gray_r, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "#重みの数　　784　X　10\n",
    "w = tf.Variable(tf.truncated_normal([784,10],stddev=0.1))\n",
    "#バイアスは10個\n",
    "w0 = tf.Variable(tf.zeros([10]))\n",
    "#総入力関数\n",
    "f = tf.matmul(x, w) + w0\n",
    "#ソフトマックス関数\n",
    "p = tf.nn.softmax(f)\n",
    "#ソフトマックス関数の出力\n",
    "t = tf.placeholder(tf.float32, [None, 10])\n",
    "loss = -tf.reduce_sum(t * tf.log(p))\n",
    "#AdamOptimizerを使用する。\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(p, 1), tf.argmax(t, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Loss: Tensor(\"Neg:0\", shape=(), dtype=float32) Accuracy: 0.2837\n",
      "Step: 1000 Loss: Tensor(\"Neg:0\", shape=(), dtype=float32) Accuracy: 0.9136\n",
      "Step: 2000 Loss: Tensor(\"Neg:0\", shape=(), dtype=float32) Accuracy: 0.9215\n",
      "Step: 3000 Loss: Tensor(\"Neg:0\", shape=(), dtype=float32) Accuracy: 0.9112\n",
      "Step: 4000 Loss: Tensor(\"Neg:0\", shape=(), dtype=float32) Accuracy: 0.9195\n",
      "Step: 5000 Loss: Tensor(\"Neg:0\", shape=(), dtype=float32) Accuracy: 0.9142\n",
      "Step: 6000 Loss: Tensor(\"Neg:0\", shape=(), dtype=float32) Accuracy: 0.9231\n",
      "Step: 7000 Loss: Tensor(\"Neg:0\", shape=(), dtype=float32) Accuracy: 0.9205\n",
      "Step: 8000 Loss: Tensor(\"Neg:0\", shape=(), dtype=float32) Accuracy: 0.9239\n",
      "Step: 9000 Loss: Tensor(\"Neg:0\", shape=(), dtype=float32) Accuracy: 0.9187\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(10000):\n",
    "    batch_xs, batch_ts = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, t: batch_ts})\n",
    "    if i % 1000 == 0:\n",
    "        loss_val, acc_val = sess.run([loss, accuracy],\n",
    "            feed_dict={x:mnist.test.images, t: mnist.test.labels})\n",
    "        print ('Step:', i ,'Loss:',loss, 'Accuracy:',acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3層　ニューラルネットワークによる画像認識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#入力\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "#入力から隠れ層への重み　784 x 64 個\n",
    "w_1 = tf.Variable(tf.truncated_normal([784,64],stddev=0.1))\n",
    "\n",
    "b_1 = tf.Variable(tf.zeros([64]))\n",
    "#隠れ層への入力\n",
    "h_1 = tf.nn.relu(tf.matmul(x,w_1) + b_1 )\n",
    "\n",
    "#出力層\n",
    "w_2 = tf.Variable(tf.truncated_normal([64,10],stddev=0.1))\n",
    "b_2 = tf.Variable(tf.zeros([10]))\n",
    "f = tf.matmul(h_1, w_2) + b_2\n",
    "#ソフトマックス関数\n",
    "p = tf.nn.softmax(f)\n",
    "\n",
    "t = tf.placeholder(tf.float32, [None, 10])\n",
    "loss = -tf.reduce_sum(t * tf.log(p))\n",
    "#loss = tf.reduce_mean(tf.square(t-p))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(p, 1), tf.argmax(t, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.1099\n",
      "Step: 100 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.8533\n",
      "Step: 200 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.8849\n",
      "Step: 300 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.899\n",
      "Step: 400 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.9034\n",
      "Step: 500 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.9097\n",
      "Step: 600 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.9148\n",
      "Step: 700 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.9201\n",
      "Step: 800 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.9269\n",
      "Step: 900 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.9269\n",
      "Step: 1000 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.931\n",
      "Step: 1100 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.93\n",
      "Step: 1200 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.9303\n",
      "Step: 1300 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.9361\n",
      "Step: 1400 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.9378\n",
      "Step: 1500 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.9378\n",
      "Step: 1600 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.9403\n",
      "Step: 1700 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.941\n",
      "Step: 1800 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.9431\n",
      "Step: 1900 Loss: Tensor(\"Neg_1:0\", shape=(), dtype=float32) Accuracy: 0.9448\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(2000):\n",
    "    batch_xs, batch_ts = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, t: batch_ts})\n",
    "    if i % 100 == 0:\n",
    "        loss_val, acc_val = sess.run([loss, accuracy],\n",
    "            feed_dict={x:mnist.test.images, t: mnist.test.labels})\n",
    "        print ('Step:', i ,'Loss:',loss, 'Accuracy:',acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "216px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
