{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 理論\n",
    "\n",
    "### 総入力関数\n",
    "\n",
    "$$\n",
    "y = w^T x+ b\n",
    "$$\n",
    "\n",
    "### softmax関数\n",
    "ロジスティック回帰では、シグモイド関数を使用して、2値分類を行いました。\n",
    "今度は、手書きの数字画像を認識するので、2値ではなく0から9までのどれかに\n",
    "分類する必要があります。このような問題を　**多クラス分類** とよびます。\n",
    "多クラス分類を行う場合は、シグモド関数ではなく、**ソフトマックス関数** と呼ばれる\n",
    "関数を使用します。\n",
    "\n",
    "ソフトマックス関数\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "softmax(y) &= \\frac{exp(x_i)}{ \\sum_{j=1}^{n} exp(x_j)}　\\tag{1.1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "理論上は式(1.1）のようになりますが、このままコンピュータで計算するとオーバーフローを起こすので\n",
    "実際のプログラミングでは以下のように変形します。\n",
    "\n",
    "任意の定数Cを分母分子に掛ける\n",
    "$$\n",
    "\\begin{align}\n",
    "softmax(y) &= \\frac{Cexp(x_i)}{ C\\sum_{j=1}^{n} exp(x_j)}　\\\\\n",
    "&=\\frac{Cexp(x_i + logC)}{ C\\sum_{j=1}^{n} exp(x_j + logC)}　\\\\\n",
    "&=\\frac{Cexp(x_i + C')}{ C\\sum_{j=1}^{n} exp(x_j + C')}　\\tag{1.2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "TensorFlowでは、softmax関数で実装されているので、理論通り考えて差し支えありません。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wataru/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/Users/wataru/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#数式(1.1)のとおりだとオーバーフローしてしまう。\n",
    "#\n",
    "import numpy as np\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "softmax(np.array([1010,1000,990]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.99954600e-01,   4.53978686e-05,   2.06106005e-09])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#数式(1.2)のとおりだと計算できる\n",
    "#\n",
    "import numpy as np\n",
    "#Cを-1000として\n",
    "C=-1000\n",
    "def softmax2(x):\n",
    "    x\n",
    "    x2 = x + C\n",
    "    return np.exp(x2) / np.sum(np.exp(x2))\n",
    "\n",
    "y = softmax2(np.array([1010,1000,990]))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の例とおおり、ソフトマックス関数の合計は1.0とななる。各値がそれぞれの多クラスの正解ラベルとなる確率を表す。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 確率の表現\n",
    "$N$個の入力データ $x_n(n=1,2,3,\\cdots,n)$ とそれに対応する正解データ　$t_n $ としたときに、<br>\n",
    "$x_n$がクラス$k$に属するときの$t_n$の$j$番目の成分は\n",
    "$$\n",
    "t_{nj}=\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & (j = k) \\\\\n",
    "0 & (j \\neq 0)\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "と表現される。\n",
    "クラス$k$に属する確率は\n",
    "$$\n",
    "\\begin{align}\n",
    "P(C=k | x) &= softmax(w^T + b )  \\\\\n",
    "&=\\frac{Cexp(w_k^T + b)}{ C\\sum_{j=1}^{n} exp(w_k^T + b)}　\\tag{1.3}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### 尤度関数\n",
    "ロジスティクス回帰と同様に尤度関数を考えると、\n",
    "\n",
    "式(1.3)より\n",
    "<br>\n",
    "<br>\n",
    "$$\n",
    "\\begin{align}\n",
    "L(w,b) &=\\prod_{n=1}^{N}\\prod_{k=1}^{K}P(C=t_{nk}|x_n)^{t_{nk}} \\\\\n",
    " &=\\prod_{n=1}^{N}\\prod_{k=1}^{K}y_{nk}^{t_nk} \\tag{1.4}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "尤度関数を最大化する重みを見つければ良いが、尤度関数は積の形をしており、計算を単純化するためには式(1.5)の対数をとり和の形で表現します。\n",
    "得られた誤差関数Eを勾配降下法で最小となる重みを計算します。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E(w,b) &= -logL(w,b) \\\\\n",
    "&= -\\sum_{n=1}^{N}\\sum_{k=1}^{K}t_{nk}logy_{nk} \\tag{1.5}\n",
    "\\end{align}\\\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "誤差関数Eの偏微分は以下のようになる。\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial w_j} &= \n",
    "\\sum_{n=1}^{N}\\sum_{k=1}^{K}\\frac{\\partial }{\\partial y_{nk}}(t_{nk}logy_{nk})\\frac{\\partial y_{nk}}{\\partial a_{nj}} \\frac{\\partial a_{nj}}{\\partial w_{nj}}\\\\\n",
    "&= - \\sum_{n=1}^{N}\\sum_{k=1}^{K}\\frac{t_{nk}}{y_{nk}}  \\frac{\\partial y_{nk}}{\\partial a_{nj}}x_n\\\\\n",
    "&= -  \\sum_{n=1}^{N}\\lgroup\\sum_{k=1}^{K}t_{nk}I_{kj}- \\sum_{k=1}t_{nl}y_{nk})x_n\\\\\n",
    "&=  - \\sum_{n=1}^{N}(t_{nj}-y_{nj})x_n \\tag{1.6}\n",
    "\\end{align}\\\n",
    "$$\n",
    "同様にバイアスに関しても偏微分すると、\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial b_j} &=  - \\sum_{n=1}^{N}(t_{nj}-y_{nj}) 　\\tag{1.7}\n",
    "\\end{align}\\\n",
    "$$\n",
    "\n",
    "最終的に\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial W} &=  - \\sum_{n=1}^{N}(t_{n}-y_{n})X_n^T 　\\tag{1.8}\n",
    "\\end{align}\\\n",
    "$$\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial b} &=  - \\sum_{n=1}^{N}(t_{n}-y_{n})　\\tag{1.9}\n",
    "\\end{align}\\\n",
    "$$\n",
    "\n",
    "\n",
    "が得られる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手書き画像認識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "#MNISTデータがダウンロードできない場合は、ファイルをMNIST_data\n",
    "#ディレクトリに展開して、以下の行を実行すると\n",
    "#取り込めます\n",
    "#mnist = input_data.read_data_sets('MNIST_data',one_hot=True)   \n",
    "images, labels = mnist.train.next_batch(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wataru/anaconda3/lib/python3.6/site-packages/matplotlib/font_manager.py:1316: UserWarning: findfont: Font family ['IPAPGothic'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdMAAADlCAYAAAAIqh2pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a191b8860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "for c, (image, label) in enumerate(zip(images, labels),start=1):\n",
    "    subplot = fig.add_subplot(2,5,c)\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    subplot.set_title('%d' % np.argmax(label))\n",
    "    subplot.imshow(image.reshape((28,28)), vmin=0, vmax=1,\n",
    "                   cmap=plt.cm.gray_r, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "#重みの数　　784　X　10\n",
    "w = tf.Variable(tf.truncated_normal([784,10],stddev=0.1))\n",
    "#バイアスは10個\n",
    "w0 = tf.Variable(tf.zeros([10]))\n",
    "#総入力関数\n",
    "f = tf.matmul(x, w) + w0\n",
    "#ソフトマックス関数\n",
    "p = tf.nn.softmax(f)\n",
    "#ソフトマックス関数の出力\n",
    "t = tf.placeholder(tf.float32, [None, 10])\n",
    "loss = -tf.reduce_sum(t * tf.log(p))\n",
    "#AdamOptimizerを使用する。\n",
    "train_step = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(p, 1), tf.argmax(t, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.0754\n",
      "Step: 100 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.7986\n",
      "Step: 200 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.8602\n",
      "Step: 300 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.8773\n",
      "Step: 400 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.8877\n",
      "Step: 500 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.8976\n",
      "Step: 600 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.901\n",
      "Step: 700 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.9055\n",
      "Step: 800 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.9095\n",
      "Step: 900 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.911\n",
      "Step: 1000 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.9118\n",
      "Step: 1100 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.913\n",
      "Step: 1200 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.9127\n",
      "Step: 1300 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.9167\n",
      "Step: 1400 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.9168\n",
      "Step: 1500 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.9186\n",
      "Step: 1600 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.9178\n",
      "Step: 1700 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.9202\n",
      "Step: 1800 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.919\n",
      "Step: 1900 Loss: Tensor(\"Neg_6:0\", shape=(), dtype=float32) Accuracy: 0.9209\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(2000):\n",
    "    batch_xs, batch_ts = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, t: batch_ts})\n",
    "    if i % 100 == 0:\n",
    "        loss_val, acc_val = sess.run([loss, accuracy],\n",
    "            feed_dict={x:mnist.test.images, t: mnist.test.labels})\n",
    "        print ('Step:', i ,'Loss:',loss, 'Accuracy:',acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3層　ニューラルネットワークによる画像認識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#入力\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "#入力から隠れ層への重み　784 x 64 個\n",
    "w_1 = tf.Variable(tf.truncated_normal([784,64],stddev=0.1))\n",
    "＃\n",
    "b_1 = tf.Variable(tf.zeros([64]))\n",
    "#隠れ層への入力\n",
    "h_1 = tf.nn.relu(tf.matmul(x,w_1) + b_1 )\n",
    "\n",
    "#出力層\n",
    "w_2 = tf.Variable(tf.truncated_normal([64,10],stddev=0.1))\n",
    "b_2 = tf.Variable(tf.zeros([10]))\n",
    "f = tf.matmul(h_1, w_2) + b_2\n",
    "#ソフトマックス関数\n",
    "p = tf.nn.softmax(f)\n",
    "\n",
    "t = tf.placeholder(tf.float32, [None, 10])\n",
    "loss = -tf.reduce_sum(t * tf.log(p))\n",
    "#loss = tf.reduce_mean(tf.square(t-p))\n",
    "#AdamOptimizerを使用する。\n",
    "train_step = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(p, 1), tf.argmax(t, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.1923\n",
      "Step: 100 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.878\n",
      "Step: 200 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.9104\n",
      "Step: 300 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.9176\n",
      "Step: 400 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.9232\n",
      "Step: 500 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.9295\n",
      "Step: 600 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.9355\n",
      "Step: 700 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.9374\n",
      "Step: 800 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.943\n",
      "Step: 900 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.9419\n",
      "Step: 1000 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.9474\n",
      "Step: 1100 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.9474\n",
      "Step: 1200 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.952\n",
      "Step: 1300 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.9518\n",
      "Step: 1400 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.9546\n",
      "Step: 1500 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.9554\n",
      "Step: 1600 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.9581\n",
      "Step: 1700 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.9559\n",
      "Step: 1800 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.9592\n",
      "Step: 1900 Loss: Tensor(\"Neg_7:0\", shape=(), dtype=float32) Accuracy: 0.9603\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(2000):\n",
    "    batch_xs, batch_ts = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, t: batch_ts})\n",
    "    if i % 100 == 0:\n",
    "        loss_val, acc_val = sess.run([loss, accuracy],\n",
    "            feed_dict={x:mnist.test.images, t: mnist.test.labels})\n",
    "        print ('Step:', i ,'Loss:',loss, 'Accuracy:',acc_val)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "216px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
