{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 理論\n",
    "\n",
    "## 総入力関数\n",
    "\n",
    "$$\n",
    "y = w^T x+ b\n",
    "$$\n",
    "\n",
    "## softmax関数\n",
    "ロジスティック回帰では、シグモイド関数を使用して、2値分類を行いました。\n",
    "今度は、手書きの数字画像を認識するので、2値ではなく0から9までのどれかに\n",
    "分類する必要があります。このような問題を　**多クラス分類** とよびます。\n",
    "多クラス分類を行う場合は、シグモド関数ではなく、**ソフトマックス関数** と呼ばれる\n",
    "関数を使用します。\n",
    "\n",
    "ソフトマックス関数\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "softmax(y) &= \\frac{exp(x_i)}{ \\sum_{j=1}^{n} exp(x_j)}　\\tag{1.1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "理論上は式(1.1）のようになりますが、このままコンピュータで計算するとオーバーフローを起こすので\n",
    "実際のプログラミングでは以下のように変形します。\n",
    "\n",
    "任意の定数Cを分母分子に掛ける\n",
    "$$\n",
    "\\begin{align}\n",
    "softmax(y) &= \\frac{Cexp(x_i)}{ C\\sum_{j=1}^{n} exp(x_j)}　\\\\\n",
    "&=\\frac{Cexp(x_i + logC)}{ C\\sum_{j=1}^{n} exp(x_j + logC)}　\\\\\n",
    "&=\\frac{Cexp(x_i + C')}{ C\\sum_{j=1}^{n} exp(x_j + C')}　\\tag{1.2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "TensorFlowでは、softmax関数で実装されているので、理論通り考えて差し支えありません。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#数式(1.1)のとおりだとオーバーフローしてしまう。\n",
    "#\n",
    "import numpy as np\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "softmax(np.array([1010,1000,990]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.99954600e-01,   4.53978686e-05,   2.06106005e-09])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#数式(1.2)のとおりだと計算できる\n",
    "#\n",
    "import numpy as np\n",
    "#Cを-1000として\n",
    "C=-1000\n",
    "def softmax2(x):\n",
    "    x\n",
    "    x2 = x + C\n",
    "    return np.exp(x2) / np.sum(np.exp(x2))\n",
    "\n",
    "y = softmax2(np.array([1010,1000,990]))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の例とおおり、ソフトマックス関数の合計は1.0とななる。各値がそれぞれの多クラスの正解ラベルとなる確率を表す。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 確率の表現\n",
    "$N$個の入力データ $x_n(n=1,2,3,\\cdots,n)$ とそれに対応する正解データ　$t_n $ としたときに、<br>\n",
    "$x_n$がクラス$k$に属するときの$t_n$の$j$番目の成分は\n",
    "$$\n",
    "t_{nj}=\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & (j = k) \\\\\n",
    "0 & (j \\neq 0)\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "と表現される。\n",
    "クラス$k$に属する確率は\n",
    "$$\n",
    "\\begin{align}\n",
    "P(C=k | x) &= softmax(w^T + b )  \\\\\n",
    "&=\\frac{Cexp(w_k^T + b)}{ C\\sum_{j=1}^{n} exp(w_k^T + b)}　\\tag{1.3}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### 尤度関数\n",
    "ロジスティクス回帰と同様に尤度関数を考えると、\n",
    "\n",
    "式(1.3)より\n",
    "<br>\n",
    "<br>\n",
    "$$\n",
    "\\begin{align}\n",
    "L(w,b) &=\\prod_{n=1}^{N}\\prod_{k=1}^{K}P(C=t_{nk}|x_n)^{t_{nk}} \\\\\n",
    " &=\\prod_{n=1}^{N}\\prod_{k=1}^{K}y_{nk}^{t_nk} \\tag{1.4}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "尤度関数を最大化する重みを見つければ良いが、尤度関数は積の形をしており、計算を単純化するためには式(1.5)の対数をとり和の形で表現します。\n",
    "得られた誤差関数Eを勾配降下法で最小となる重みを計算します。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E(w,b) &= -logL(w,b) \\\\\n",
    "&= -\\sum_{n=1}^{N}\\sum_{k=1}^{K}t_{nk}logy_{nk} \\tag{1.5}\n",
    "\\end{align}\\\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "誤差関数Eの偏微分は以下のようになる。\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial w_j} &= \n",
    "\\sum_{n=1}^{N}\\sum_{k=1}^{K}\\frac{\\partial }{\\partial y_{nk}}(t_{nk}logy_{nk})\\frac{\\partial y_{nk}}{\\partial a_{nj}} \\frac{\\partial a_{nj}}{\\partial w_{nj}}\\\\\n",
    "&= - \\sum_{n=1}^{N}\\sum_{k=1}^{K}\\frac{t_{nk}}{y_{nk}}  \\frac{\\partial y_{nk}}{\\partial a_{nj}}x_n\\\\\n",
    "&= -  \\sum_{n=1}^{N}\\lgroup\\sum_{k=1}^{K}t_{nk}I_{kj}- \\sum_{k=1}t_{nl}y_{nk})x_n\\\\\n",
    "&=  - \\sum_{n=1}^{N}(t_{nj}-y_{nj})x_n \\tag{1.6}\n",
    "\\end{align}\\\n",
    "$$\n",
    "同様にバイアスに関しても偏微分すると、\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial b_j} &=  - \\sum_{n=1}^{N}(t_{nj}-y_{nj}) 　\\tag{1.7}\n",
    "\\end{align}\\\n",
    "$$\n",
    "\n",
    "最終的に\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial W} &=  - \\sum_{n=1}^{N}(t_{n}-y_{n})X_n^T 　\\tag{1.8}\n",
    "\\end{align}\\\n",
    "$$\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial b} &=  - \\sum_{n=1}^{N}(t_{n}-y_{n})　\\tag{1.9}\n",
    "\\end{align}\\\n",
    "$$\n",
    "\n",
    "\n",
    "が得られる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手書き画像認識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f9680ece7091>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "#MNISTデータがダウンロードできない場合は、ファイルをMNIST_data\n",
    "#ディレクトリに展開して、以下の行を実行すると\n",
    "#取り込めます\n",
    "#mnist = input_data.read_data_sets('MNIST_data',one_hot=True)   \n",
    "images, labels = mnist.train.next_batch(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "for c, (image, label) in enumerate(zip(images, labels),start=1):\n",
    "    subplot = fig.add_subplot(2,5,c)\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    subplot.set_title('%d' % np.argmax(label))\n",
    "    subplot.imshow(image.reshape((28,28)), vmin=0, vmax=1,\n",
    "                   cmap=plt.cm.gray_r, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "#重みの数　　784　X　10\n",
    "w = tf.Variable(tf.truncated_normal([784,10],stddev=0.1))\n",
    "#バイアスは10個\n",
    "w0 = tf.Variable(tf.zeros([10]))\n",
    "#総入力関数\n",
    "f = tf.matmul(x, w) + w0\n",
    "#ソフトマックス関数\n",
    "p = tf.nn.softmax(f)\n",
    "#ソフトマックス関数の出力\n",
    "t = tf.placeholder(tf.float32, [None, 10])\n",
    "loss = -tf.reduce_sum(t * tf.log(p))\n",
    "#AdamOptimizerを使用する。\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(p, 1), tf.argmax(t, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(10000):\n",
    "    batch_xs, batch_ts = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, t: batch_ts})\n",
    "    if i % 1000 == 0:\n",
    "        loss_val, acc_val = sess.run([loss, accuracy],\n",
    "            feed_dict={x:mnist.test.images, t: mnist.test.labels})\n",
    "        print ('Step:', i ,'Loss:',loss, 'Accuracy:',acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3層　ニューラルネットワークによる画像認識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#入力\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "#入力から隠れ層への重み　784 x 64 個\n",
    "w_1 = tf.Variable(tf.truncated_normal([784,64],stddev=0.1))\n",
    "\n",
    "b_1 = tf.Variable(tf.zeros([64]))\n",
    "#隠れ層への入力\n",
    "h_1 = tf.nn.relu(tf.matmul(x,w_1) + b_1 )\n",
    "\n",
    "#出力層\n",
    "w_2 = tf.Variable(tf.truncated_normal([64,10],stddev=0.1))\n",
    "b_2 = tf.Variable(tf.zeros([10]))\n",
    "f = tf.matmul(h_1, w_2) + b_2\n",
    "#ソフトマックス関数\n",
    "p = tf.nn.softmax(f)\n",
    "\n",
    "t = tf.placeholder(tf.float32, [None, 10])\n",
    "loss = -tf.reduce_sum(t * tf.log(p))\n",
    "#loss = tf.reduce_mean(tf.square(t-p))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(p, 1), tf.argmax(t, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(2000):\n",
    "    batch_xs, batch_ts = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, t: batch_ts})\n",
    "    if i % 100 == 0:\n",
    "        loss_val, acc_val = sess.run([loss, accuracy],\n",
    "            feed_dict={x:mnist.test.images, t: mnist.test.labels})\n",
    "        print ('Step:', i ,'Loss:',loss, 'Accuracy:',acc_val)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "216px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
